---
title: 'EDS 230: Assignment 5'
author: Grace Bianchi, Erika Egg
output:
  slidy_presentation:
    highlight: pygments
  html_document: default
  pdf_document: default
  ioslides_presentation:
    highlight: pygments
  beamer_presentation:
    highlight: pygments
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(sensitivity)
library(tidyverse)
library(lubridate)
library(reldist)
library(purrr)
library(ggpubr)
```

```{r source_func}
# Source our R script with our function (a combination of at least two performance measures)
# We have chosen our two measures (relative error for max flow and relative error for low flow) because we figured extremes would be good areas to check model performance, as they deviate more from the majority of values in a normal distribution
source("R/compute_extremes.R")

# Read in sager data
sager = read.table("Data/sager.txt", header=T)
head(sager)

# Add date
sager = sager %>% mutate(date = paste(day,month,year, sep="/"))
sager$date = as.Date(sager$date,"%d/%m/%Y")

# Sample output (sager must be read in first)
compute_extremes(m = sager$model, o = sager$obs, wy = sager$wy)
# First value is error for minimum flow averaged across water years
# Second value is error for maximum flow averaged across water years
# Third value is error as a combined metric of the first two (equally weighted by default)
```

```{r prep_msage}
# multiple results - lets say we've run the model for multiple years, 
#each column  is streamflow for a different parameter set
msage = read.table("Data/sagerm.txt", header=T)

# keep track of number of simulations (e.g results for each parameter set) 
# use as a column names
nsim = ncol(msage)
snames = sprintf("S%d",seq(from=1, to=nsim))
colnames(msage)=snames


# lets say we know the start date from our earlier output
msage$date = sager$date
msage$month = sager$month
msage$year = sager$year
msage$day = sager$day
msage$wy = sager$wy

# lets add observed
msage = left_join(msage, sager[,c("obs","date")], by=c("date"))

head(msage)
```

```{r calibration}
# subset for split sample calibration
short_msage = subset(msage, wy < 1975)

res = short_msage %>% select(-date, -month, -day, -year, -wy, -obs ) %>%
  map_df(compute_extremes, o=short_msage$obs, wy=short_msage$wy)
# note here we use map_df to get a dataframe back 


# interesting to look at range of metrics - could use this to decide on
# acceptable values
summary(res)

# we can add a row that links with simulation number
res$sim = snames

# graph range of performance measures
resl = res %>% pivot_longer(-sim, names_to="metric", values_to="value")

ggplot(resl, aes(metric, value))+geom_boxplot()+facet_wrap(~metric, scales="free")


# select the best and worst ones based on the combined metric
best = res[which.max(res$combined),]
worst = res[which.min(res$combined),]
```

